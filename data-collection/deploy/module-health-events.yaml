AWSTemplateFormatVersion: "2010-09-09"
Description: Retrieves AWS Health Events details accross AWS organization
Parameters:
  DatabaseName:
    Type: String
    Description: Name of the Athena database to be created to hold lambda information
    Default: optimization_data
  DestinationBucket:
    Type: String
    Description: Name of the S3 Bucket that exists or needs to be created to hold costanomaly information
    AllowedPattern: (?=^.{3,63}$)(?!^(\d+\.)+\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])\.)*([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])$)
  DestinationBucketARN:
    Type: String
    Description: ARN of the S3 Bucket that exists or needs to be created to hold costanomaly information
  ManagementRoleName:
    Type: String
    Description: The name of the IAM role that will be deployed in the management account which can retrieve AWS Organization data. KEEP THE SAME AS WHAT IS DEPLOYED INTO MANAGEMENT ACCOUNT
  CFDataName:
    Type: String
    Description: The name of what this cf is doing.
    Default: health-events
  GlueRoleARN:
    Type: String
    Description: Arn for the Glue Crawler role
  Schedule:
    Type: String
    Description: EventBridge Schedule to trigger the data collection
    Default: "rate(14 days)"
  ResourcePrefix:
    Type: String
    Description: This prefix will be placed in front of all roles created. Note you may wish to add a dash at the end to make more readable
  RegionsInScope:
    Type: String
    Description: "Comma Delimited list of AWS regions from which data about resources will be collected. Example: us-east-1,eu-west-1,ap-northeast-1"
  LambdaAnalyticsARN:
    Type: String
    Description: Arn of lambda for Analytics
  AccountCollectorLambdaARN:
    Type: String
    Description: Arn of the Account Collector Lambda
  StepFunctionTemplate:
    Type: String
    Description: JSON representation of common StepFunction template
  StepFunctionExecutionRoleARN:
    Type: String
    Description: Common role for Step Function execution
  SchedulerExecutionRoleARN:
    Type: String
    Description: Common role for module Scheduler execution

Outputs:
  StepFunctionARN:
    Description: ARN for the module's Step Function
    Value: !GetAtt ModuleStepFunction.Arn

Resources:
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${ResourcePrefix}${CFDataName}-LambdaRole"
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
        Version: 2012-10-17
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: !Sub "${CFDataName}-ManagementAccount-LambdaRole"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "sts:AssumeRole"
                Resource: !Sub "arn:aws:iam::*:role/${ManagementRoleName}" # Need to assume a Read role in all Management accounts
        - PolicyName: "S3-Access"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:PutObject"
                  - "s3:GetObject"
                  - "s3:PutObjectAcl"
                Resource:
                  - !Sub "${DestinationBucketARN}/*"
              - Effect: "Allow"
                Action:
                  - "s3:ListBucket"
                Resource:
                  - !Sub "${DestinationBucketARN}"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28 # Resource found with an explicit name, this disallows updates that require replacement of this resource
            reason: "Need explicit name to identify role actions"

  LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ResourcePrefix}${CFDataName}-Lambda'
      Description: !Sub "Lambda function to retrieve ${CFDataName}"
      Runtime: python3.10
      Architectures: [x86_64]
      Code:
        ZipFile: |
          import os
          import json
          import logging
          import jmespath
          from datetime import date, datetime, timedelta, timezone

          import boto3

          logger = logging.getLogger()
          logger.setLevel(getattr(logging, os.environ.get('LOG_LEVEL', 'INFO').upper(), logging.INFO))

          BUCKET_NAME = os.environ['BUCKET_NAME']
          ROLENAME = os.environ['ROLENAME']
          PREFIX = os.environ['PREFIX']
          REGIONS = [r.strip() for r in os.environ.get("REGIONS", "").split(',') if r]
          if len(REGIONS) > 0:
              REGIONS.append('global')
          LOOKBACK = int(os.environ['LOOKBACK'])
          TMP_FILE = "/tmp/data.json"

          mapping = {
              'payerAccountId': 'payerAccountId',
              'awsAccountId': 'awsAccountId',
              'entityValue': 'entityValue',
              'entityUrl': 'entityUrl',
              'tags': 'tags',
              'eventArn': 'event.arn',
              'service': 'event.service',
              'eventTypeCode': 'event.eventTypeCode',
              'eventTypeCategory': 'event.eventTypeCategory',
              'region': 'event.region',
              'availabilityZone': 'event.availabilityZone',
              'eventScopeCode': 'eventScopeCode',
              'startTime': 'event.startTime',
              'endTime': 'event.endTime',
              'lastUpdatedTime': 'event.lastUpdatedTime',
              'statusCode': 'event.statusCode',
              'latestDescription': 'eventDescription.latestDescription',
              'eventMetadata': 'eventMetadata',
              'deprecated_versions': 'deprecated_versions',
              'entityStatusCode': 'entityStatusCode',
              'entityLastUpdatedTime': 'entityLastUpdatedTime',
          }

          def to_json(obj):
              """json helper for date, time and data"""
              def _date_transformer(obj):
                  return obj.isoformat() if isinstance(obj, (date, datetime)) else None
              return json.dumps(obj, default=_date_transformer)

          def chunks(lst, n):
              """Yield successive n-sized chunks from a list."""
              for i in range(0, len(lst), n):
                  yield lst[i:i + n]

          def int_to_datetime(int_time):
              return datetime.datetime.utcfromtimestamp(int_time/1000)

          def iterate_paginated_results(client, function, search, params=None):
              yield from client.get_paginator(function).paginate(**(params or {})).search(search)

          def calculate_dates(bucket, s3_path):
              """ Timeboxes the range of events by seeking the most recent data collection date from the last 90 days """
              end_date = datetime.now(timezone.utc)
              start_date = end_date - timedelta(days=LOOKBACK)
              # Check the create time of objects in the S3 bucket
              paginator = boto3.client('s3').get_paginator('list_objects_v2')
              contents = sum( [page.get('Contents', []) for page in paginator.paginate(Bucket=bucket, Prefix=s3_path)], [])
              last_modified_date = get_last_modified_date(contents)
              if last_modified_date and last_modified_date >= start_date:
                  start_date = last_modified_date
              return start_date, end_date

          def get_last_modified_date(contents):
              """ Helper for calculate_dates """
              last_modified_dates = [obj['LastModified'] for obj in contents]
              last_modified_dates_within_90_days = [datetime for datetime in last_modified_dates if datetime >= datetime.now(timezone.utc) - timedelta(days=90)]
              if last_modified_dates_within_90_days:
                  return max(last_modified_dates_within_90_days)
              return None

          def search(function, args=None, expression='@'):
              compiled = jmespath.compile(expression)
              args = args or {}
              while True:
                  page = function(**args)
                  results = compiled.search(dict(page))
                  if isinstance(results, list):
                      yield from results
                  else:
                      # Yield result directly if it is not a list.
                      yield results
                  if 'nextToken' in page and page['nextToken']:
                      args['next_token'] = page['nextToken']
                  else:
                      break

          def pull_event_details(event):
              event_arn = event['arn']
              health_client = event['health_client']
              accounts = list(search(
                  function=health_client.describe_affected_accounts_for_organization,
                  args={'eventArn': event_arn},
                  expression='affectedAccounts',
              ))

              # describe_event_details_for_organization only can get 10 per call
              details = []
              affected_entities = []
              for account_chunk in list(chunks(accounts, 10)):
                  details += list(search(
                      function=health_client.describe_event_details_for_organization,
                      args=dict(
                          organizationEventDetailFilters=[{'eventArn':event_arn, 'awsAccountId': account} for account in account_chunk]
                      ),
                      expression='successfulSet',
                  ))
                  affected_entities += list(search(
                      function=health_client.describe_affected_entities_for_organization,
                      args=dict(
                          organizationEntityFilters=[{'eventArn':event_arn, 'awsAccountId': account} for account in account_chunk]
                      ),
                      expression='entities',
                  ))

              #>>>CUT
              details[0]['eventMetadata'] = {
                          'deprecated_versions': 'my-old-version'
                      }

              affected_entities.append({
                      'entityArn': 'my-entityArn',
                      'eventArn': event_arn,
                      'entityValue': 'my-entityValue',
                      'entityUrl': 'my-entityUrl',
                      'awsAccountId': '317256447485',
                      'lastUpdatedTime': datetime(2024, 2, 1),
                      'statusCode': 'IMPAIRED',
                      'tags': {
                          'my-tag01': 'taggy'
                      }
                  }
              )
              affected_entities.append({
                      'entityArn': 'my-entityArn2',
                      'eventArn': event_arn,
                      'entityValue': 'my-entityValue2',
                      'entityUrl': 'my-entityUrl2',
                      'awsAccountId': '317256447485',
                      'lastUpdatedTime': datetime(2024, 2, 1),
                      'statusCode': 'UNKNOWN',
                      'tags': {
                          'my-tag01': 'taggy2'
                      }
                  }
              )
              #<<<CUT

              # match affected and descriptions
              event_details_per_affected = []
              if len(affected_entities) == 0:
                  event['event'] = event
                  event_details_per_affected.append(event)
              for affected_entity in affected_entities:
                  account = affected_entity['awsAccountId']
                  event_arn = affected_entity['eventArn']
                  affected_entity['entityStatusCode'] = affected_entity.pop('statusCode', None)
                  affected_entity['entityLastUpdatedTime'] = affected_entity.pop('lastUpdatedTime', None)
                  detail = jmespath.search(f"[?awsAccountId=='{account}']|[?event.arn=='{event_arn}']", details)
                  for detail_rec in detail:
                      metadata = detail_rec.get('eventMetadata') or {}
                      detail_rec['deprecated_versions'] = metadata.pop('deprecated_versions', None)
                  merged_dict = {**event, **affected_entity}
                  merged_dict = {**merged_dict, **detail[0]}
                  if isinstance(merged_dict['event'].get('startTime'), int):
                      merged_dict['event']['startTime'] =int_to_datetime(merged_dict['event']['startTime'])
                  if isinstance(merged_dict['event'].get('endTime'), int):
                      merged_dict['event']['endTime'] =int_to_datetime(merged_dict['event']['endTime'])
                  if isinstance(merged_dict['event'].get('lastUpdatedTime'), int):
                      merged_dict['event']['lastUpdatedTime'] =int_to_datetime(merged_dict['event']['lastUpdatedTime'])
                  event_details_per_affected.append(merged_dict)
              return event_details_per_affected

          def lambda_handler(event, context): #pylint: disable=unused-argument
              """ this lambda collects AWS Health Events data
              and must be called from the corresponding Step Function to orchestrate
              """
              logger.info(f"Event data: {event}")
              if 'account' not in event:
                  raise ValueError(
                      "Please do not trigger this Lambda manually."
                      "Find the corresponding state machine in Step Functions and Trigger from there."
                  )
              account = json.loads(event["account"])
              account_id = account["account_id"]
              payer_id = account["payer_id"]

              creds = boto3.client('sts').assume_role(
                  RoleArn=f"arn:aws:iam::{account_id}:role/{ROLENAME}",
                  RoleSessionName="data_collection"
              )['Credentials']
              health_client = boto3.client(
                  'health',
                  aws_access_key_id=creds['AccessKeyId'],
                  aws_secret_access_key=creds['SecretAccessKey'],
                  aws_session_token=creds['SessionToken'],
              )
              start_from, start_to = calculate_dates(BUCKET_NAME, PREFIX)
              logger.info(f"Collecting events from {start_from} to {start_to}")
              args = {
                  'maxResults':100,
                  'filter': {
                      'startTime': {
                          'from': start_from.strftime('%Y-%m-%dT%H:%M:%S%z'),
                          'to': start_to.strftime('%Y-%m-%dT%H:%M:%S%z'),
                      },
                  }
              }
              if len(REGIONS) > 0:
                  args['filter']['regions'] = REGIONS

              count = 0
              try:
                  with open(TMP_FILE, "w", encoding='utf-8') as f:
                      for _, event in enumerate(search(health_client.describe_events_for_organization, args, expression='events')):
                          #if event['eventTypeCode'] == 'AWS_VPN_REDUNDANCY_LOSS':
                          #    continue # who cares?
                          event['health_client'] = health_client
                          event['payerAccountId'] = payer_id
                          all_detailed_events = pull_event_details(event)
                          flatten_events = jmespath.search("[].{"+', '.join([f'{k}: {v}' for k, v in mapping.items()]) + "}", all_detailed_events)
                          for flatten_event in flatten_events:
                              f.write(to_json(flatten_event) + '\n')
                              count += 1
                  if count > 0:
                      r = open(TMP_FILE, 'r')
                      key = datetime.now(timezone.utc).strftime(f"{PREFIX}/{PREFIX}-data/payer_id={payer_id}/year=%Y/month=%m/day=%d/%Y-%m-%d-%H-%M-%S.json")
                      boto3.client('s3').upload_file(TMP_FILE, BUCKET_NAME, key)
                      logger.info(f'Uploaded {count} records to s3://{BUCKET_NAME}/{key}')
                  else:
                      logger.info(f"No records found")
              except Exception as exc:
                  if 'Organizational View feature is not enabled' in str(exc):
                      logger.error(f"Payer {payer_id} do not have Organizational View. See https://docs.aws.amazon.com/health/latest/ug/enable-organizational-view-in-health-console.html")
                  else:
                      logger.error(f"Error: {exc}")

              return {"status":"200","Recorded":f'"{count}"'}
      Handler: "index.lambda_handler"
      MemorySize: 2688
      Timeout: 600
      Role: !GetAtt LambdaRole.Arn
      Environment:
        Variables:
          BUCKET_NAME: !Ref DestinationBucket
          PREFIX: !Ref CFDataName
          ROLENAME: !Ref ManagementRoleName
          REGIONS: !Ref RegionsInScope
          LOOKBACK: 90
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W89 # Lambda functions should be deployed inside a VPC
            reason: "No need for VPC in this case"
          - id: W92 #  Lambda functions should define ReservedConcurrentExecutions to reserve simultaneous executions
            reason: "No need for simultaneous execution"

  LogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub "/aws/lambda/${LambdaFunction}"
      RetentionInDays: 60

  HealthEventsTable:
    Type: AWS::Glue::Table
    Properties:
      CatalogId: !Ref "AWS::AccountId"
      DatabaseName: !Ref DatabaseName
      TableInput:
        Name: !Join ['_', !Split [ '-', !Sub "${CFDataName}_data" ]]
        Owner: owner
        Retention: 0
        TableType: EXTERNAL_TABLE
        Parameters:
          EXTERNAL: 'TRUE'
          UPDATED_BY_CRAWLER: !Sub '${ResourcePrefix}${CFDataName}-Crawler'
          compressionType: none
          typeOfData: file
        PartitionKeys:
          - Name: payer_id
            Type: string
          - Name: year
            Type: string
          - Name: month
            Type: string
          - Name: day
            Type: string
        StorageDescriptor:
          BucketColumns: []
          InputFormat: org.apache.hadoop.mapred.TextInputFormat
          Location: !Sub "s3://${DestinationBucket}/${CFDataName}/${CFDataName}-data/"
          OutputFormat: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          SerdeInfo:
            Parameters:
              paths: availabilityZone,awsAccountId,endTime,entityUrl,entityValue,eventArn,eventMetadata,eventScopeCode,eventTypeCategory,eventTypeCode,lastUpdatedTime,latestDescription,payerAccountId,region,service,startTime,statusCode,tags
              serialization.format: '1'
            SerializationLibrary: org.openx.data.jsonserde.JsonSerDe
          StoredAsSubDirectories: false
          Columns:
            - Name: payeraccountid
              Type: string
            - Name: awsaccountid
              Type: string
            - Name: entityvalue
              Type: string
            - Name: entityurl
              Type: string
            - Name: tags
              Type: string
            - Name: eventarn
              Type: string
            - Name: service
              Type: string
            - Name: eventtypecode
              Type: string
            - Name: eventtypecategory
              Type: string
            - Name: region
              Type: string
            - Name: availabilityzone
              Type: string
            - Name: eventscopecode
              Type: string
            - Name: starttime
              Type: string
            - Name: endtime
              Type: string
            - Name: lastupdatedtime
              Type: string
            - Name: statuscode
              Type: string
            - Name: latestdescription
              Type: string
            - Name: eventmetadata
              Type: string

  Crawler:
    Type: AWS::Glue::Crawler
    Properties:
      Name: !Sub '${ResourcePrefix}${CFDataName}-Crawler'
      Role: !Ref GlueRoleARN
      DatabaseName: !Ref DatabaseName
      Targets:
        S3Targets:
          - Path: !Sub "s3://${DestinationBucket}/${CFDataName}/${CFDataName}-data/"
      Configuration: |
        {
          "Version":1.0,
          "CrawlerOutput": {
            "Tables":{
              "AddOrUpdateBehavior":"MergeNewColumns"
            }
          },
          "CreatePartitionIndex":true
        }

  ModuleStepFunction:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      StateMachineName: !Sub '${ResourcePrefix}${CFDataName}-StateMachine'
      StateMachineType: STANDARD
      RoleArn: !Ref StepFunctionExecutionRoleARN
      DefinitionString: !Ref StepFunctionTemplate
      DefinitionSubstitutions:
        AccountCollectorLambdaARN: !Ref AccountCollectorLambdaARN
        ModuleLambdaARN: !GetAtt LambdaFunction.Arn
        Crawlers: !Sub '["${ResourcePrefix}${CFDataName}-Crawler"]'
        CollectionType: "Payers"
        Params: ''
        Module: !Ref CFDataName
        DeployRegion: !Ref AWS::Region
        Account: !Ref AWS::AccountId
        Prefix: !Ref ResourcePrefix

  ModuleRefreshSchedule:
    Type: 'AWS::Scheduler::Schedule'
    Properties:
      Description: !Sub 'Scheduler for the ODC ${CFDataName} module'
      Name: !Sub '${ResourcePrefix}${CFDataName}-RefreshSchedule'
      ScheduleExpression: !Ref Schedule
      State: ENABLED
      FlexibleTimeWindow:
        MaximumWindowInMinutes: 30
        Mode: 'FLEXIBLE'
      Target:
        Arn: !GetAtt ModuleStepFunction.Arn
        RoleArn: !Ref SchedulerExecutionRoleARN

  AnalyticsExecutor:
    Type: Custom::LambdaAnalyticsExecutor
    Properties:
      ServiceToken: !Ref LambdaAnalyticsARN
      Name: !Ref CFDataName